{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from methods import *\n",
    "import pickle, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean: 552\n",
    "polygon: 276\n",
    "kelvin: 63\n",
    "gotham: 51\n",
    "lomo: 60\n",
    "nashville: 55\n",
    "toaster: 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, filename):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(obj, handle)\n",
    "\n",
    "def load_obj(filename):\n",
    "    if not os.path.isfile(filename):\n",
    "        print('Pickle {} does not exist.'.format(filename))\n",
    "        return None\n",
    "    with open(filename, 'rb') as handle:\n",
    "        obj = pickle.load(handle)\n",
    "    return obj\n",
    "\n",
    "def read_features(p_path, trigger_type_aux_str=None):\n",
    "    report = pd.read_csv(p_path)\n",
    "    if trigger_type_aux_str is not None:\n",
    "        indexes = []\n",
    "        for i in range(len(report)):\n",
    "            col = report['trigger_type_aux'].iloc[i]\n",
    "            if (trigger_type_aux_str in col.lower()) or (col.lower() == 'none'):\n",
    "                indexes.append(i)\n",
    "        report = report.iloc[indexes]\n",
    "    initial_columns = report.columns\n",
    "    col_model_label = report['model_label'].copy(deep=True)\n",
    "    for c in initial_columns:\n",
    "        if not c.endswith('mean_diff') and not c.endswith('std_diff'):\n",
    "            del report[c]\n",
    "    features = report.values\n",
    "    labels = np.array([int(col_model_label.iloc[i] == 'backdoor') for i in range(len(report))])\n",
    "    return abs(features), labels\n",
    "\n",
    "def evaluate_classifier(train_x, train_y, test_x, test_y):\n",
    "    clf = svm.SVC(kernel='linear', probability=True)\n",
    "    clf.fit(train_x, train_y)\n",
    "    y_score = clf.predict(test_x)\n",
    "    y_pred = clf.predict_proba(test_x)\n",
    "    roc_auc = roc_auc_score(y_true=test_y, y_score=y_score)\n",
    "    cross_entropy = log_loss(y_true=test_y, y_pred=y_pred)\n",
    "    return roc_auc, cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot trigger-size vs ROC using 5-fold cross validation for Square Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_square_sizes = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "dict_square_sizes = {size:index*2 for index, size in enumerate(list_square_sizes)}\n",
    "roc_auc_scores, roc_auc_err = [], []\n",
    "xent_scores, xent_err = [], []\n",
    "trigger_type_aux_str = 'polygon'\n",
    "print(f'trigger_type_aux_str = {trigger_type_aux_str}\\n')\n",
    "for size, index in dict_square_sizes.items():\n",
    "    path = 'confusion-reports/ics_svm/round2-train-dataset/round2-train-dataset_squares.csv'\n",
    "    X, y = read_features(path, trigger_type_aux_str)\n",
    "    \n",
    "    print(f'selecting columns {index} and {index+1}')\n",
    "    X = X[:, index:index+2]\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    cv_scores_roc, cv_scores_xent = [], []\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        X_train, y_train = X[train_index, :], y[train_index] # square_diffs have indexes 0,1 !!!\n",
    "        X_test, y_test = X[test_index, :], y[test_index] # square_diffs have indexes 0,1 !!!\n",
    "        roc, xent = evaluate_classifier(X_train, y_train, X_test, y_test)\n",
    "        cv_scores_roc.append(roc)\n",
    "        cv_scores_xent.append(xent)\n",
    "    mean_roc, std_roc = np.mean(cv_scores_roc), np.std(cv_scores_roc)\n",
    "    mean_xent, std_xent = np.mean(cv_scores_xent), np.std(cv_scores_xent)\n",
    "    print(f'size={size}, index={index}: mean_roc={mean_roc}, std_roc={std_roc}, mean_xent={mean_xent}, std_xent={std_xent}\\n')\n",
    "    \n",
    "    roc_auc_scores.append(mean_roc)\n",
    "    roc_auc_err.append(std_roc)\n",
    "    xent_scores.append(mean_xent)\n",
    "    xent_err.append(std_xent)\n",
    "\n",
    "plt.figure(figsize=(10, 6)).patch.set_color('white')\n",
    "plt.errorbar(list_square_sizes, roc_auc_scores, roc_auc_err, marker='o', label='all models')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('square trigger size')\n",
    "plt.ylabel('ROC AUC for SVM classifier')\n",
    "plt.xticks(list_square_sizes)\n",
    "plt.title(f'trigger size vs ROC (all models)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6)).patch.set_color('white')\n",
    "plt.errorbar(list_square_sizes, xent_scores, xent_err, marker='o', label='all models')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('square trigger size')\n",
    "plt.ylabel('Cross-Entropy for SVM classifier')\n",
    "plt.xticks(list_square_sizes)\n",
    "plt.title(f'trigger size vs Cross-Entropy (all models)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot trigger-size vs ROC using 5-fold cross validation for Filters data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_filters = ['gotham', 'kelvin', 'lomo', 'nashville', 'toaster']\n",
    "dict_filter_indexes = {size:index*2 for index, size in enumerate(list_filters)}\n",
    "roc_auc_scores, roc_auc_err = [], []\n",
    "xent_scores, xent_err = [], []\n",
    "for filter_name, index in dict_filter_indexes.items():\n",
    "    path = 'confusion-reports/ics_svm/round2-train-dataset/round2-train-dataset_filters.csv'\n",
    "    X, y = read_features(path, filter_name)\n",
    "    \n",
    "    print(f'selecting columns {index} and {index+1}')\n",
    "    X = X[:, index:index+2]\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    cv_scores_roc, cv_scores_xent = [], []\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        X_train, y_train = X[train_index, :], y[train_index] # square_diffs have indexes 0,1 !!!\n",
    "        X_test, y_test = X[test_index, :], y[test_index] # square_diffs have indexes 0,1 !!!\n",
    "        roc, xent = evaluate_classifier(X_train, y_train, X_test, y_test)\n",
    "        cv_scores_roc.append(roc)\n",
    "        cv_scores_xent.append(xent)\n",
    "    mean_roc, std_roc = np.mean(cv_scores_roc), np.std(cv_scores_roc)\n",
    "    mean_xent, std_xent = np.mean(cv_scores_xent), np.std(cv_scores_xent)\n",
    "    print(f'size={size}, index={index}: mean_roc={mean_roc}, std_roc={std_roc}, mean_xent={mean_xent}, std_xent={std_xent}\\n')\n",
    "    \n",
    "    roc_auc_scores.append(mean_roc)\n",
    "    roc_auc_err.append(std_roc)\n",
    "    xent_scores.append(mean_xent)\n",
    "    xent_err.append(std_xent)\n",
    "\n",
    "plt.figure(figsize=(10, 6)).patch.set_color('white')\n",
    "plt.errorbar(list_filters, roc_auc_scores, roc_auc_err, marker='o', label='all models')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('square trigger size')\n",
    "plt.ylabel('ROC AUC for SVM classifier')\n",
    "plt.xticks(list_filters)\n",
    "plt.title(f'trigger size vs ROC (all models)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6)).patch.set_color('white')\n",
    "plt.errorbar(list_filters, xent_scores, xent_err, marker='o', label='all models')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('square trigger size')\n",
    "plt.ylabel('Cross-Entropy for SVM classifier')\n",
    "plt.xticks(list_filters)\n",
    "plt.title(f'trigger size vs Cross-Entropy (all models)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stratified 5-fold validation for all data (selected square + 5 filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv = r'confusion-reports\\ics_svm\\round2-train-dataset\\round2-train-dataset_square25-filters.csv'\n",
    "# dict_trigger_indexes = { 'polygon': 0, 'gotham': 2, 'kelvin': 4, 'lomo': 6, 'nashville': 8, 'toaster': 10 }\n",
    "trigger_type_aux_str = None\n",
    "print(f'trigger_type_aux_str={trigger_type_aux_str}')\n",
    "X, y = read_features(path_csv, trigger_type_aux_str) # clean data is automatically added\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "scores_roc, scores_xent = [], []\n",
    "for index, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    X_train, y_train = X[train_index, :], y[train_index]\n",
    "    X_test, y_test = X[test_index, :], y[test_index]\n",
    "#     print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    roc, xent = evaluate_classifier(X_train, y_train, X_test, y_test)\n",
    "#     print(f'split #{index}: roc={roc:.4f}, xent={xent:.4f}')\n",
    "    scores_roc.append(roc)\n",
    "    scores_xent.append(xent)\n",
    "print(f'avg roc ={sum(scores_roc) / len(scores_roc)}')\n",
    "print(f'std roc ={np.std(scores_roc)}')\n",
    "print()\n",
    "print(f'avg xent={sum(scores_xent) / len(scores_xent)}')\n",
    "print(f'std roc ={np.std(scores_xent)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test model using CV on entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv = r'confusion-reports\\ics_svm\\round2-train-dataset\\round2-train-dataset_square25-filters.csv'\n",
    "trigger_type_aux_str = None\n",
    "print(f'trigger_type_aux_str={trigger_type_aux_str}')\n",
    "X, y = read_features(path_csv, trigger_type_aux_str) # clean data is automatically added\n",
    "print(f'X.shape={X.shape}')\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "scores_roc, scores_xent = [], []\n",
    "\n",
    "for index, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    X_train, y_train = X[train_index, :], y[train_index]\n",
    "    X_test, y_test = X[test_index, :], y[test_index]\n",
    "    roc, xent = evaluate_classifier(X_train, y_train, X_test, y_test)\n",
    "    scores_roc.append(roc)\n",
    "    scores_xent.append(xent)\n",
    "\n",
    "mean_roc, std_roc = np.mean(scores_roc), np.std(scores_roc)\n",
    "mean_xent, std_xent = np.mean(scores_xent), np.std(scores_xent)\n",
    "print(f'mean roc: {mean_roc}, std roc: {std_roc}')\n",
    "print(f'mean xent: {mean_xent}, std xent: {std_xent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot (mean, std)  of clean data vs (mean, std) of backdoored data (polygon or instagram filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path_csv = r'confusion-reports\\ics_svm\\round2-train-dataset\\round2-train-dataset_square20-gotham-kelvin-lomo-nashville-toaster.csv'\n",
    "# dict_trigger_indexes = { 'polygon': 0, 'gotham': 2, 'kelvin': 4, 'lomo': 6, 'nashville': 8, 'toaster': 10 }\n",
    "# X_train, y_train = read_features(p_path=path_csv) # clean data is automatically added\n",
    "\n",
    "# for trigger_type, idx in dict_trigger_indexes.items():\n",
    "#     print(trigger_type, idx)\n",
    "#     x_axis = X_train[:, idx]\n",
    "#     y_axis = X_train[:, idx+1]\n",
    "    \n",
    "#     list_labels = [['clean', 'backdoored'][y] for y in y_train]\n",
    "#     list_colors = [['#1f77b4', 'orange'][y] for y in y_train]\n",
    "    \n",
    "#     plt.figure(figsize=(10, 6)).patch.set_color('white')\n",
    "#     plt.scatter(x_axis, y_axis, c=list_colors, s=20, cmap=plt.cm.Paired)\n",
    "\n",
    "# #     count_backdoored = 0\n",
    "# #     count_clean = 0\n",
    "# #     for label_int, label_name, color in [(0, 'clean', '#1f77b4'), (1, 'backdoored', 'orange')]:\n",
    "# #         mask = (y_train == label_int)\n",
    "# #         if label_int == 0:\n",
    "# #             count_clean = mask.sum()\n",
    "# #         else:\n",
    "# #             count_backdoored = mask.sum()\n",
    "# #         plt.scatter(x_axis[mask], y_axis[mask], c=color, zorder=10, s=20, cmap=plt.cm.Paired, label=label_name)\n",
    "\n",
    "# #     plt.xlim([0, 20])\n",
    "# #     plt.ylim([0, 6])\n",
    "# #     plt.axvline(x=3, ymin=y_axis.min(), ymax=y_axis.max(), color='k')\n",
    "#     plt.xlabel('mean diff')\n",
    "#     plt.ylabel('std diff')\n",
    "#     plt.title(f'({count_clean} clean models) VS ({count_backdoored} {trigger_type}-trigger models)')\n",
    "#     plt.grid()\n",
    "# #     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train meta-model using square data and filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = read_features(r'confusion-reports/ics_svm/round2-train-dataset/round2-train-dataset_square25-filters.csv', None)\n",
    "model = svm.SVC(kernel='linear', probability=True)\n",
    "model.fit(X_train, y_train)\n",
    "save_obj(model, r'..\\metamodel_svm_square25_filters_black_square.pickle')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 [[1.86744785 1.27493119 1.18450713 1.47024345 1.65593791 0.80267477\n",
      "  0.95568627 1.2098341  1.90642571 1.42624617 3.84788251 1.72699928]]\n",
      "f0 [[1.82715303 1.26201016 1.19891316 1.46478623 1.59655792 0.79464245\n",
      "  0.32524949 0.30400246 1.88940006 1.43893212 3.80975634 1.75787288]]\n",
      "\n",
      "x1 [[0.4220762  0.47042182 1.10502267 0.54304481 6.54966593 0.51066893\n",
      "  1.02778816 0.74778295 1.11660028 1.0599544  6.34732199 0.49520218]]\n",
      "f1 [[0.39484879 0.50877406 1.09632185 0.82257093 5.03916481 1.66733004\n",
      "  0.27484182 0.17397539 0.82403234 0.65039082 4.63860634 1.67463233]]\n"
     ]
    }
   ],
   "source": [
    "f0 = np.array([1.82715303, 1.26201016, 1.19891316, 1.46478623, 1.59655792, 0.79464245, 0.32524949, 0.30400246, 1.88940006, 1.43893212, 3.80975634, 1.75787288]).reshape(1, -1)\n",
    "f1 = np.array([0.39484879, 0.50877406, 1.09632185, 0.82257093, 5.03916481, 1.66733004, 0.27484182, 0.17397539, 0.82403234, 0.65039082, 4.63860634, 1.67463233]).reshape(1, -1)\n",
    "\n",
    "x0 = X_train[0, :].reshape(1, -1)#.tolist()\n",
    "x1 = X_train[1, :].reshape(1, -1)#.tolist()\n",
    "\n",
    "print('x0', x0)\n",
    "print('f0', f0)#.tolist())\n",
    "print()\n",
    "print('x1', x1)\n",
    "print('f1', f1)#.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.89523142 0.10476858]]\n",
      "[0]\n",
      "\n",
      "[[0.8867273 0.1132727]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f2 = np.array([0.38871786, 0.50383109, 1.10065868, 0.82881629, 4.98052385, 1.66656768, 0.2645593, 0.16752021, 0.80955854, 0.65046561, 4.61183241, 1.67506552]).reshape(1, -1)\n",
    "print(model.predict_proba(f1))\n",
    "print(model.predict(f1))\n",
    "print()\n",
    "print(model.predict_proba(f2))\n",
    "print(model.predict(f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.42872318])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = load_obj(r'..\\metamodel_svm_square25_filters_black_square.pickle')\n",
    "loaded_model._probA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge or simplify datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_from_dataset():\n",
    "    df = pd.read_csv(r'confusion-reports\\ics_svm\\round2-train-dataset\\round2-train-dataset_square20-gotham-kelvin-lomo-nashville-toaster.csv')\n",
    "    for col_to_delete in ['square_mean_diff', 'square_std_diff', 'square_mean', 'square_std']:\n",
    "        del df[col_to_delete]\n",
    "    df.to_csv(r'confusion-reports\\ics_svm\\round2-train-dataset\\round2-train-dataset_filters.csv', index=False)\n",
    "    print('done')\n",
    "\n",
    "def merge_datasets():\n",
    "    df1 = pd.read_csv(r'confusion-reports\\ics_svm\\round2-train-dataset\\round2-train-dataset_filters.csv')\n",
    "    df2 = pd.read_csv(r'confusion-reports\\ics_svm\\round2-train-dataset\\round2-train-dataset_squares.csv')\n",
    "    for col in ['square25_mean_diff', 'square25_std_diff', 'square25_mean', 'square25_std']:\n",
    "        df1[col] = df2[col]\n",
    "    \n",
    "#     series_data = []\n",
    "#     for i in range(len(df1)):\n",
    "#         trigger_type = df1.iloc[i]['trigger_type']\n",
    "#         trigger_type_option = df1.iloc[i]['trigger_type_option']\n",
    "#         if trigger_type == 'instagram':\n",
    "#             series_data.append(trigger_type_option.replace('XForm', '').replace('Filter', ''))\n",
    "#         else:\n",
    "#             if trigger_type == 'None':\n",
    "#                 series_data.append(trigger_type)\n",
    "#             else:\n",
    "#                 series_data.append(f'{trigger_type}-{trigger_type_option}')\n",
    "#     df1['trigger_type_aux'] = series_data\n",
    "    \n",
    "    new_order_for_columns = [\n",
    "        'model_name', 'model_architecture', 'model_label',\n",
    "        'trigger_type_aux', # 'trigger_type', 'trigger_type_option',\n",
    "\n",
    "        'square25_mean_diff', 'square25_std_diff',\n",
    "        'gotham_mean_diff', 'gotham_std_diff',\n",
    "        'kelvin_mean_diff', 'kelvin_std_diff',\n",
    "        'lomo_mean_diff', 'lomo_std_diff',\n",
    "        'nashville_mean_diff', 'nashville_std_diff',\n",
    "        'toaster_mean_diff', 'toaster_std_diff',\n",
    "\n",
    "        'clean_mean', 'clean_std',\n",
    "        'square25_mean', 'square25_std',\n",
    "        'gotham_mean', 'gotham_std',\n",
    "        'kelvin_mean', 'kelvin_std',\n",
    "        'lomo_mean', 'lomo_std',\n",
    "        'nashville_mean', 'nashville_std',\n",
    "        'toaster_mean', 'toaster_std',\n",
    "\n",
    "        'trigger_color', 'num_classes',\n",
    "    ]\n",
    "    df1 = df1[new_order_for_columns]\n",
    "    df1.to_csv(r'confusion-reports\\ics_svm\\round2-train-dataset\\round2-train-dataset_square25-filters.csv', index=False)\n",
    "    print('done')\n",
    "merge_datasets()\n",
    "# select_columns_from_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
