{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss, make_scorer, accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, concatenate, Input\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.metrics import BinaryCrossentropy, Precision, Recall, AUC\n",
    "from tensorflow.keras import regularizers\n",
    "from methods import *\n",
    "import torch\n",
    "import pickle, os\n",
    "import skopt\n",
    "from skopt import BayesSearchCV, gp_minimize\n",
    "from skopt.space import Integer\n",
    "from skopt.space import Real\n",
    "from skopt.space import Categorical\n",
    "from skopt.utils import use_named_args\n",
    "import shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%config IPCompleter.greedy=True\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    use_arch = True\n",
    "    path_train = r'confusion-reports\\ics_fc\\round4-train-dataset\\round4-train-dataset_fc_synthetic_polygon-all-gray_filters_0-1007_shuffled.csv'\n",
    "    X, y = read_features(path_train, trigger_type_aux_str=None, arch=None, data='diffs', label_type='binary', append_arch=use_arch, arch_one_hot=use_arch)\n",
    "    # y = MultiLabelBinarizer().fit_transform(y)\n",
    "    X_features, X_arch = X[:,:12], X[:,12:]\n",
    "\n",
    "    percent_training = 1.0\n",
    "    n_samples = X.shape[0]\n",
    "    np.random.seed(int(time.time()))\n",
    "    indexes_train = np.random.choice(n_samples, int(n_samples * percent_training), replace=False).tolist()\n",
    "    indexes_test = [i for i in range(n_samples) if i not in indexes_train]\n",
    "\n",
    "    X_features_train, X_arch_train, y_train = X_features[indexes_train, :], X_arch[indexes_train, :], y[indexes_train]\n",
    "    print('train shapes:', X_features_train.shape, X_arch_train.shape, y_train.shape)\n",
    "    if len(indexes_test) > 0:\n",
    "        X_features_test, X_arch_test, y_test =  X_features[indexes_test, :], X_arch[indexes_test, :], y[indexes_test]\n",
    "        print('test shapes:', X_features_test.shape, X_arch_test.shape, y_test.shape)\n",
    "    else:\n",
    "        X_features_test, X_arch_test, y_test = None, None, None\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # scaler.fit(X_train[:,:12])\n",
    "    # X_train[:,:12] = scaler.transform(X_train[:,:12])\n",
    "    # X_test[:,:12] = scaler.transform(X_test[:,:12])\n",
    "    shape_features, shape_arch = X_features.shape[1], X_arch.shape[1]\n",
    "\n",
    "    input_features = Input(shape=(shape_features,), name='input_features')\n",
    "    embedding_features = Dense(10, activation='relu', name='embedding_features')(input_features)\n",
    "    input_arch = Input(shape=(shape_arch,), name='input_arch')\n",
    "    embedding_arch = Dense(6, activation='relu', name='embedding_arch')(input_arch)\n",
    "    combined = concatenate([embedding_features, embedding_arch], name='combined')\n",
    "    embedding = Dense(10, activation='relu', name='embedding')(combined)\n",
    "    output = Dense(1, activation='sigmoid', name='output')(embedding)\n",
    "    model = Model(inputs=[input_features, input_arch], outputs=output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(name='precision'), Recall(name='recall'), AUC(name='auc')])\n",
    "    # model.summary()\n",
    "\n",
    "    history = model.fit(x=[X_features_train, X_arch_train], y=y_train, epochs=100, batch_size=8, verbose=0, validation_split=0.2)\n",
    "\n",
    "    if len(indexes_test) > 0:\n",
    "        y_pred = model.predict([X_features_test, X_arch_test])\n",
    "    else:\n",
    "        y_pred = model.predict([X_features_train, X_arch_train])\n",
    "    \n",
    "    ce_loss = 0.0\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        t = y_test[i] if len(indexes_test) > 0 else y_train[i]\n",
    "        p = y_pred[i]\n",
    "        ce_loss += -(t * np.log(p) + (1. - t) * np.log(1. - p))\n",
    "    ce_loss = ce_loss[0] / y_pred.shape[0]\n",
    "    print(f'CE loss = {ce_loss}\\ndone')\n",
    "\n",
    "    the_time = datetime.now().strftime('%Y-%m-%d_%Hh%Mm%Ss')\n",
    "    folder = fr'round4_neural_networks_two_inputs_binary/{the_time}_test-CE={ce_loss:.3f}_input={X.shape[1]}_train-count={len(indexes_train)}_test-count={len(indexes_test)}'\n",
    "    keras_save(model, folder, name='model')\n",
    "\n",
    "    # if scaler is not None:\n",
    "    #     save_obj(scaler, folder, 'scaler')\n",
    "\n",
    "    L, C = 1, 5\n",
    "    plt.figure(figsize=(40,8)).patch.set_color('white')\n",
    "\n",
    "    plt.subplot(L,C,1)\n",
    "    plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "    if 'val_accuracy' in history.history:\n",
    "        plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(L,C,2)\n",
    "    plt.plot(history.history['loss'], label='train loss')\n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='val loss')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(L,C,3)\n",
    "    plt.plot(history.history['precision'], label='train precision')\n",
    "    if 'val_precision' in history.history:\n",
    "        plt.plot(history.history['val_precision'], label='val precision')\n",
    "    plt.title('model precision')\n",
    "    plt.ylabel('precision')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(L,C,4)\n",
    "    plt.plot(history.history['recall'], label='train recall')\n",
    "    if 'val_recall' in history.history:\n",
    "        plt.plot(history.history['val_recall'], label='val recall')\n",
    "    plt.title('model recall')\n",
    "    plt.ylabel('recall')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(L,C,5)\n",
    "    plt.plot(history.history['auc'], label='train auc')\n",
    "    if 'val_auc' in history.history:\n",
    "        plt.plot(history.history['val_auc'], label='val auc')\n",
    "    plt.title('model auc')\n",
    "    plt.ylabel('auc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.gcf().savefig(f'{folder}/plots.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pt in [0.9, 0.9]:\n",
    "    for _ in range(10):\n",
    "        use_arch = True\n",
    "        path_train = r'confusion-reports\\ics_fc\\round4-train-dataset\\round4-train-dataset_fc_synthetic_polygon-all-gray_filters_0-1007_shuffled.csv'\n",
    "        X, y = read_features(path_train, trigger_type_aux_str=None, arch=None, data='diffs', label_type='backdoor_code_2', append_arch=use_arch, arch_one_hot=use_arch)\n",
    "        y = MultiLabelBinarizer().fit_transform(y)\n",
    "        X_features, X_arch = X[:,:12], X[:,12:]\n",
    "\n",
    "        percent_training = pt\n",
    "        n_samples = X.shape[0]\n",
    "        np.random.seed(int(time.time()))\n",
    "        indexes_train = np.random.choice(n_samples, int(n_samples * percent_training), replace=False).tolist()\n",
    "        indexes_test = [i for i in range(n_samples) if i not in indexes_train]\n",
    "\n",
    "        X_features_train, X_arch_train, y_train = X_features[indexes_train, :], X_arch[indexes_train, :], y[indexes_train]\n",
    "        print('train shapes:', X_features_train.shape, X_arch_train.shape, y_train.shape)\n",
    "        \n",
    "        if len(indexes_test) > 0:\n",
    "            X_features_test, X_arch_test, y_test =  X_features[indexes_test, :], X_arch[indexes_test, :], y[indexes_test]\n",
    "            print('test shapes:', X_features_test.shape, X_arch_test.shape, y_test.shape)\n",
    "        else:\n",
    "            X_features_test, X_arch_test, y_test = None, None, None\n",
    "        \n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_features_train)\n",
    "        X_features_train = scaler.transform(X_features_train)\n",
    "        if len(indexes_test) > 0 and scaler is not None:\n",
    "            X_features_test = scaler.transform(X_features_test)\n",
    "\n",
    "        shape_features, shape_arch = X_features.shape[1], X_arch.shape[1]\n",
    "\n",
    "        input_features = Input(shape=(shape_features,), name='input_features')\n",
    "        embedding_features = Dense(10, activation='relu', name='embedding_features')(input_features)\n",
    "        input_arch = Input(shape=(shape_arch,), name='input_arch')\n",
    "        embedding_arch = Dense(6, activation='relu', name='embedding_arch')(input_arch)\n",
    "        combined = concatenate([embedding_features, embedding_arch], name='combined')\n",
    "        embedding = Dense(12, activation='relu', name='embedding')(combined)\n",
    "        output = Dense(7, activation='sigmoid', name='output')(embedding)\n",
    "        model = Model(inputs=[input_features, input_arch], outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(name='precision'), Recall(name='recall'), AUC(name='auc')])\n",
    "        # model.summary()\n",
    "\n",
    "        history = model.fit(x=[X_features_train, X_arch_train], y=y_train, epochs=40, batch_size=8, verbose=0, validation_split=0.2)\n",
    "\n",
    "        if len(indexes_test) > 0:\n",
    "            y_pred = model.predict([X_features_test, X_arch_test])\n",
    "        else:\n",
    "            y_pred = model.predict([X_features_train, X_arch_train])\n",
    "\n",
    "        ce_loss = 0.0\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            t = y_test[i] if len(indexes_test) > 0 else y_train[i]\n",
    "            p = y_pred[i]\n",
    "            t = 1 if t[1:].sum() > 0 else 0\n",
    "            v = sorted(enumerate(p), key=lambda x: -x[1])\n",
    "            label, proba = v[0]\n",
    "            if label == 0:\n",
    "                proba = 1 - proba\n",
    "            ce_loss += -(t * np.log(proba) + (1. - t) * np.log(1. - proba))\n",
    "        ce_loss = ce_loss / y_pred.shape[0]\n",
    "        print(f'CE loss = {ce_loss}\\ndone')\n",
    "\n",
    "\n",
    "        the_time = datetime.now().strftime('%Y-%m-%d_%Hh%Mm%Ss')\n",
    "        folder = fr'round4_neural_networks_bernoulli-2/{the_time}_test-CE={ce_loss:.3f}_input={X.shape[1]}_train-count={len(indexes_train)}_test-count={len(indexes_test)}'\n",
    "        keras_save(model, folder, name='model')\n",
    "\n",
    "        if scaler is not None:\n",
    "            save_obj(scaler, folder, 'scaler')\n",
    "\n",
    "        L, C = 1, 5\n",
    "        plt.figure(figsize=(40,8)).patch.set_color('white')\n",
    "\n",
    "        plt.subplot(L,C,1)\n",
    "        plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "        if 'val_accuracy' in history.history:\n",
    "            plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        plt.subplot(L,C,2)\n",
    "        plt.plot(history.history['loss'], label='train loss')\n",
    "        if 'val_loss' in history.history:\n",
    "            plt.plot(history.history['val_loss'], label='val loss')\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        plt.subplot(L,C,3)\n",
    "        plt.plot(history.history['precision'], label='train precision')\n",
    "        if 'val_precision' in history.history:\n",
    "            plt.plot(history.history['val_precision'], label='val precision')\n",
    "        plt.title('model precision')\n",
    "        plt.ylabel('precision')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        plt.subplot(L,C,4)\n",
    "        plt.plot(history.history['recall'], label='train recall')\n",
    "        if 'val_recall' in history.history:\n",
    "            plt.plot(history.history['val_recall'], label='val recall')\n",
    "        plt.title('model recall')\n",
    "        plt.ylabel('recall')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        plt.subplot(L,C,5)\n",
    "        plt.plot(history.history['auc'], label='train auc')\n",
    "        if 'val_auc' in history.history:\n",
    "            plt.plot(history.history['val_auc'], label='val auc')\n",
    "        plt.title('model auc')\n",
    "        plt.ylabel('auc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.gcf().savefig(f'{folder}/plots.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_arch = True\n",
    "path_train = r'confusion-reports\\ics_fc\\round4-train-dataset\\round4-train-dataset_fc_synthetic_polygon-all-gray_filters_0-1007_shuffled.csv'\n",
    "X, y = read_features(path_train, trigger_type_aux_str=None, arch=None, data='diffs', label_type='backdoor_code_2', append_arch=use_arch, arch_one_hot=use_arch)\n",
    "y = MultiLabelBinarizer().fit_transform(y)\n",
    "\n",
    "percent_training = 0.9\n",
    "n_samples = X.shape[0]\n",
    "np.random.seed(int(time.time()))\n",
    "indexes_train = np.random.choice(n_samples, int(n_samples * percent_training), replace=False).tolist()\n",
    "indexes_test = [i for i in range(n_samples) if i not in indexes_train]\n",
    "\n",
    "X_train, y_train, X_test, y_test = X[indexes_train, :], y[indexes_train], X[indexes_test, :], y[indexes_test]\n",
    "print('train shapes:', X_train.shape, y_train.shape)\n",
    "print('test shapes:', X_test.shape, y_test.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[:,:12])\n",
    "X_train[:,:12] = scaler.transform(X_train[:,:12])\n",
    "X_test[:,:12] = scaler.transform(X_test[:,:12])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=X.shape[1], activation='relu'))#, kernel_regularizer=regularizers.l1(0.0001)))#, kernel_constraint=maxnorm(5)))\n",
    "model.add(Dense(15, activation='relu')) #, kernel_regularizer=regularizers.l1(0.0001)))#, kernel_constraint=maxnorm(5)))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(name='precision'), Recall(name='recall'), AUC(name='auc')])\n",
    "history = model.fit(X_train, y_train, epochs=75, batch_size=8, verbose=0, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "ce_loss = 0.0\n",
    "print_messages = False\n",
    "for i in range(y_pred.shape[0]):\n",
    "    t, p = y_test[i] if len(indexes_test) > 0 else y_train[i], y_pred[i]\n",
    "    t = 1 if t[1:].sum() > 0 else 0\n",
    "    v = sorted(enumerate(p), key=lambda x: -x[1])\n",
    "    label, proba = v[0]\n",
    "    if label == 0:\n",
    "        proba = 1 - proba\n",
    "    if print_messages:\n",
    "        print(t, '\\n', p)\n",
    "        print('true binary class:', t)\n",
    "        print(f'predicted proba: {p}')\n",
    "        print()\n",
    "    ce_loss += -(t * np.log(proba) + (1. - t) * np.log(1. - proba))\n",
    "ce_loss = ce_loss / y_pred.shape[0]\n",
    "print(f'CE loss = {ce_loss}\\ndone')\n",
    "\n",
    "the_time = datetime.now().strftime('%Y-%m-%d_%Hh%Mm%Ss')\n",
    "folder = fr'round4_neural_networks_bernoulli_backdoors_normalized/{the_time}_test-CE={ce_loss:.3f}_input={X.shape[1]}_train-count={len(indexes_train)}_test-count={len(indexes_test)}'\n",
    "keras_save(model, folder, name='model')\n",
    "if scaler is not None:\n",
    "    save_obj(scaler, folder, 'scaler')\n",
    "\n",
    "L, C = 1, 5\n",
    "plt.figure(figsize=(40,8)).patch.set_color('white')\n",
    "\n",
    "plt.subplot(L,C,1)\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "if 'val_accuracy' in history.history:\n",
    "    plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(L,C,2)\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(L,C,3)\n",
    "plt.plot(history.history['precision'], label='train precision')\n",
    "if 'val_precision' in history.history:\n",
    "    plt.plot(history.history['val_precision'], label='val precision')\n",
    "plt.title('model precision')\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(L,C,4)\n",
    "plt.plot(history.history['recall'], label='train recall')\n",
    "if 'val_recall' in history.history:\n",
    "    plt.plot(history.history['val_recall'], label='val recall')\n",
    "plt.title('model recall')\n",
    "plt.ylabel('recall')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(L,C,5)\n",
    "plt.plot(history.history['auc'], label='train auc')\n",
    "if 'val_auc' in history.history:\n",
    "    plt.plot(history.history['val_auc'], label='val auc')\n",
    "plt.title('model auc')\n",
    "plt.ylabel('auc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.gcf().savefig(f'{folder}/plots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "use_arch = True\n",
    "path_train = r'confusion-reports\\ics_fc\\round4-train-dataset\\round4-train-dataset_fc_synthetic_polygon-all-gray_filters_0-1007_shuffled.csv'\n",
    "X, y = read_features(path_train, trigger_type_aux_str=None, arch=None, data='diffs', label_type='binary', append_arch=use_arch, arch_one_hot=use_arch)\n",
    "# X_0, y_0 = read_features(path_train, trigger_type_aux_str=None, arch=None, data='diffs', label_type='backdoor_code_0', append_arch=use_arch, arch_one_hot=use_arch)\n",
    "# X_1, y_1 = read_features(path_train, trigger_type_aux_str=None, arch=None, data='diffs', label_type='backdoor_code_0', append_arch=use_arch, arch_one_hot=use_arch)\n",
    "\n",
    "percent_training = 0.9\n",
    "n_samples = X.shape[0]\n",
    "np.random.seed(int(time.time()))\n",
    "indexes_train = np.random.choice(n_samples, int(n_samples * percent_training), replace=False).tolist()\n",
    "indexes_test = [i for i in range(n_samples) if i not in indexes_train]\n",
    "\n",
    "X_train, y_train, X_test, y_test = X[indexes_train, :], y[indexes_train], X[indexes_test, :], y[indexes_test]\n",
    "print('train shapes:', X_train.shape, y_train.shape)\n",
    "print('test shapes:', X_test.shape, y_test.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[:,:12])\n",
    "X_train[:,:12] = scaler.transform(X_train[:,:12])\n",
    "X_test[:,:12] = scaler.transform(X_test[:,:12])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X.shape[1], activation='relu')) # logistic regression: only one dense layer with 7 units, input_size and softmax\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(name='precision'), Recall(name='recall'), AUC(name='auc')])\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=0, validation_split=0.2)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "ce_loss = 0.0\n",
    "for i in range(y_pred.shape[0]):\n",
    "    t, p = y_test[i], y_pred[i]\n",
    "    ce_loss += -(t * np.log(p) + (1. - t) * np.log(1. - p))\n",
    "ce_loss = ce_loss[0] / y_pred.shape[0]\n",
    "print(f'CE loss (test) = {ce_loss}\\ndone')\n",
    "\n",
    "the_time = datetime.now().strftime('%Y-%m-%d_%Hh%Mm%Ss')\n",
    "folder = fr'round4_neural_networks_binary_classification_normalized/{the_time}_test-CE={ce_loss:.3f}_input={X.shape[1]}_train-count={len(indexes_train)}_test-count={len(indexes_test)}'\n",
    "keras_save(model, folder, name='model')\n",
    "if scaler is not None:\n",
    "    save_obj(scaler, folder, 'scaler')\n",
    "\n",
    "L, C = 1, 5\n",
    "plt.figure(figsize=(40,8)).patch.set_color('white')\n",
    "\n",
    "plt.subplot(L,C,1)\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(L,C,2)\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(L,C,3)\n",
    "plt.plot(history.history['precision'], label='train precision')\n",
    "plt.plot(history.history['val_precision'], label='val precision')\n",
    "plt.title('model precision')\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(L,C,4)\n",
    "plt.plot(history.history['recall'], label='train recall')\n",
    "plt.plot(history.history['val_recall'], label='val recall')\n",
    "plt.title('model recall')\n",
    "plt.ylabel('recall')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(L,C,5)\n",
    "plt.plot(history.history['auc'], label='train auc')\n",
    "plt.plot(history.history['val_auc'], label='val auc')\n",
    "plt.title('model auc')\n",
    "plt.ylabel('auc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.gcf().savefig(f'{folder}/plots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_load(r'round4_neural_networks_all_backdoors\\2021-01-17_14h03m11s_test-CE=0.497_input=20_train-count=907_test-count=101')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_folder = 'neural_networks_separate_backdoors_round_4'\n",
    "for folder in os.listdir(base_folder):\n",
    "    model = keras_load(os.path.join(base_folder, folder), model_name='model')\n",
    "    print(folder)    \n",
    "    print(model.summary())\n",
    "    print('===================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
