{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from methods import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def select_columns_from_dataset():\n",
    "    df = pd.read_csv(r'confusion-reports\\ics_fc\\round3-train-dataset\\round3-train-dataset_fc_square-30-random_filters.csv')\n",
    "#     for col_to_delete in ['square30_r_mean_diff', 'square30_r_std_diff', 'square30_r_mean', 'square30_r_std']:\n",
    "    for col_to_delete in ['square30_r_mean_diff', 'square30_r_std_diff', 'square30_r_mean', 'square30_r_std']:\n",
    "        del df[col_to_delete]\n",
    "    df.to_csv(r'confusion-reports\\ics_fc\\round3-train-dataset\\round3-train-dataset_filters.csv', index=False)\n",
    "\n",
    "def merge_datasets():\n",
    "#     for size in [10, 20, 25, 30, 35, 40, 45, 50]:\n",
    "#     for size in [25, 30, 35, 40, 45, 50]:\n",
    "    for size in [30]:\n",
    "#         path = fr'confusion-reports\\ics_fc\\round3-train-dataset\\round3-train-dataset_fc_square-{size}-random_filters.csv'\n",
    "        path = fr'confusion-reports\\ics_svm\\round3-train-dataset\\round3-train-dataset_square-{size}_filters.csv'\n",
    "        df_to_modify_and_save = pd.read_csv(path)\n",
    "        df_to_copy_columns_from = pd.read_csv(fr'confusion-reports\\round3-columns.csv')\n",
    "        df_to_modify_and_save['architecture_code'] = df_to_copy_columns_from['architecture_code']\n",
    "#         for col in [f'square{size}_mean_diff', f'square{size}_std_diff', f'square{size}_mean', f'square{size}_std']:\n",
    "#             df_to_modify_and_save[col] = df_to_copy_columns_from[col]\n",
    "        new_order_for_columns = [\n",
    "            'model_name', 'model_architecture', 'architecture_code', 'model_label', 'trigger_type_aux',\n",
    "\n",
    "            f'square{size}_mean_diff', f'square{size}_std_diff',\n",
    "#             f'square{size}_r_mean_diff', f'square{size}_r_std_diff',\n",
    "            'gotham_mean_diff', 'gotham_std_diff',\n",
    "            'kelvin_mean_diff', 'kelvin_std_diff',\n",
    "            'lomo_mean_diff', 'lomo_std_diff',\n",
    "            'nashville_mean_diff', 'nashville_std_diff',\n",
    "            'toaster_mean_diff', 'toaster_std_diff',\n",
    "\n",
    "            'clean_mean', 'clean_std',\n",
    "            f'square{size}_mean', f'square{size}_std',\n",
    "#             f'square{size}_r_mean', f'square{size}_r_std',\n",
    "            'gotham_mean', 'gotham_std',\n",
    "            'kelvin_mean', 'kelvin_std',\n",
    "            'lomo_mean', 'lomo_std',\n",
    "            'nashville_mean', 'nashville_std',\n",
    "            'toaster_mean', 'toaster_std',\n",
    "\n",
    "            'trigger_color', 'num_classes',\n",
    "        ]\n",
    "        df_to_modify_and_save = df_to_modify_and_save[new_order_for_columns]\n",
    "        df_to_modify_and_save.to_csv(path, index=False)\n",
    "\n",
    "def correct_column_in_dataset():\n",
    "    df_with_correct_column = pd.read_csv(r'confusion-reports\\ics_svm\\round3-train-dataset\\round3-columns.csv')\n",
    "    column = 'trigger_type_aux'\n",
    "    for size in [10, 15, 20, 25,30, 35, 40, 45, 50]:\n",
    "        file = fr'confusion-reports\\ics_svm\\round3-train-dataset\\round3-train-dataset_square-{size}-filters_all-classes_gray.csv'\n",
    "        df_to_be_corrected = pd.read_csv(file)\n",
    "        df_to_be_corrected[column] = df_with_correct_column[column]\n",
    "        df_to_be_corrected.to_csv(file, index=False)\n",
    "\n",
    "def create_architecture_code():\n",
    "    df_columns = pd.read_csv(r'confusion-reports\\round3-columns.csv')\n",
    "    list_codes = []\n",
    "    for i in range(len(df_columns)):\n",
    "        model_architecture = df_columns['model_architecture'].iloc[i]\n",
    "        arch_code = encode_architecture(model_architecture)\n",
    "        if arch_code is None:\n",
    "            print(f'Error at index {i}')\n",
    "            break\n",
    "        list_codes.append(arch_code)\n",
    "    df_columns['architecture_code'] = list_codes\n",
    "    df_columns = df_columns[['model_name', 'poisoned', 'model_architecture', 'architecture_code', 'trigger_type_aux', 'trigger_type', 'instagram_filter_type', 'polygon_side_count']]\n",
    "    df_columns.to_csv(r'confusion-reports\\round3-columns.csv', index=False)\n",
    "    \n",
    "merge_datasets()\n",
    "# select_columns_from_dataset()\n",
    "# correct_column_in_dataset()\n",
    "# create_architecture_code()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
